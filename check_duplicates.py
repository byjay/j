#!/usr/bin/env python3
"""
í˜„ì¬ conversation.js íŒŒì¼ì˜ ì¤‘ë³µ ìƒíƒœë¥¼ ìƒì„¸íˆ ë¶„ì„í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import json
from pathlib import Path
from collections import defaultdict

def analyze_duplicates(file_path):
    """íŒŒì¼ì˜ ì¤‘ë³µ ìƒíƒœë¥¼ ë¶„ì„"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # conversationModuleData ì¶”ì¶œ
    start_marker = 'const conversationModuleData = '
    end_marker = ';\n\nlet currentConversationCategory'
    
    start_idx = content.find(start_marker)
    end_idx = content.find(end_marker)
    
    if start_idx == -1 or end_idx == -1:
        print("âŒ conversationModuleDataë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return
    
    data_str = content[start_idx + len(start_marker):end_idx].strip()
    data = json.loads(data_str)
    
    print(f"ğŸ“Š íŒŒì¼ ì¤‘ë³µ ë¶„ì„ ê²°ê³¼\n")
    print(f"ì´ ì¹´í…Œê³ ë¦¬ ìˆ˜: {len(data)}\n")
    
    # ê° ì¹´í…Œê³ ë¦¬ë³„ ì¤‘ë³µ í™•ì¸
    total_convs = 0
    total_duplicates = 0
    
    print(f"{'ì¹´í…Œê³ ë¦¬':<20} {'í•­ëª©ìˆ˜':<10} {'ìœ ë‹ˆí¬':<10} {'ì¤‘ë³µ':<10} {'ìƒíƒœ':<10}")
    print("=" * 70)
    
    for category_key, category_data in data.items():
        convs = category_data.get('conversations', [])
        total_convs += len(convs)
        
        # ì¼ë³¸ì–´ ë¬¸ì¥ìœ¼ë¡œ ì¤‘ë³µ ê²€ì‚¬
        seen = set()
        duplicates = []
        
        for i, conv in enumerate(convs):
            jp = conv['question']['jp']
            if jp in seen:
                duplicates.append((i, jp))
            else:
                seen.add(jp)
        
        unique_count = len(seen)
        dup_count = len(duplicates)
        total_duplicates += dup_count
        
        status = "âœ… OK" if dup_count == 0 else f"âš ï¸ {dup_count}ê°œ"
        
        print(f"{category_key:<20} {len(convs):<10} {unique_count:<10} {dup_count:<10} {status:<10}")
        
        # ì¤‘ë³µ í•­ëª© ìƒì„¸ í‘œì‹œ (ì²˜ìŒ 3ê°œë§Œ)
        if duplicates and len(duplicates) > 0:
            print(f"  ì¤‘ë³µ ì˜ˆì‹œ:")
            for idx, (pos, jp_text) in enumerate(duplicates[:3]):
                print(f"    [{pos}] {jp_text[:40]}...")
            if len(duplicates) > 3:
                print(f"    ... ì™¸ {len(duplicates) - 3}ê°œ ë”")
    
    print("=" * 70)
    print(f"{'í•©ê³„':<20} {total_convs:<10} {total_convs - total_duplicates:<10} {total_duplicates:<10}")
    print()
    
    if total_duplicates > 0:
        print(f"âš ï¸  ì—¬ì „íˆ {total_duplicates}ê°œì˜ ì¤‘ë³µ í•­ëª©ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"ğŸ’¡ deduplicate_conversations.py ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
    else:
        print(f"âœ… ì¤‘ë³µ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤!")

if __name__ == '__main__':
    file_path = Path(r'f:\genmini\japness\ë³€í™˜\JAP_BONG\js\conversation.js')
    analyze_duplicates(file_path)
